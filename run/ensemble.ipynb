{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c599ee-4b0f-439c-b828-bc306161df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def hard_voting(file_list):\n",
    "    # 모든 파일의 데이터를 저장할 리스트\n",
    "    all_data = []\n",
    "\n",
    "    # 각 파일에서 데이터 로드\n",
    "    for file in file_list:\n",
    "        with open(file, 'r') as f:\n",
    "            data = [json.loads(line) for line in f.readlines()]\n",
    "            all_data.append(data)\n",
    "\n",
    "    final_results = []\n",
    "    print(len(all_data))\n",
    "    # 각 id에 대해 투표 시작\n",
    "    for i in range(len(all_data[0])):\n",
    "        vote_result = {\"joy\": 0, \"anticipation\": 0, \"trust\": 0, \"surprise\": 0,\n",
    "                       \"disgust\": 0, \"fear\": 0, \"anger\": 0, \"sadness\": 0}\n",
    "\n",
    "        # 모든 파일의 예측 결과에 대해 투표 진행\n",
    "        for data in all_data:\n",
    "            for emotion in vote_result.keys():\n",
    "                if data[i]['output'][emotion] == 'True':\n",
    "                    vote_result[emotion] += 1\n",
    "\n",
    "        max_vote = max(vote_result.values())\n",
    "\n",
    "        if max_vote == 0:   # 만약 모든 감정이 False라면 \n",
    "            output_dict = {emotion: 'True' if emotion == 'joy' else 'False'\n",
    "                           for emotion in vote_result.keys()}\n",
    "        elif len(file_list)<=3:\n",
    "            output_dict = {emotion: 'True' if vote == max_vote else 'False'\n",
    "                           for emotion, vote in vote_result.items()}\n",
    "        elif len(file_list)>3:\n",
    "            output_dict = {emotion: 'True' if vote >= len(file_list)/2 else 'False'\n",
    "                           for emotion, vote in vote_result.items()}\n",
    "\n",
    "        final_results.append({\"id\" : all_data[0][i]['id'], \n",
    "                              'input': all_data[0][i]['input'], \n",
    "                              'output': output_dict})\n",
    "        \n",
    "    ensemble_filename = \"+\".join([file[len(file_path):].split('.')[0] for file in file_list])\n",
    "    \n",
    "    if len(file_list)<=3:\n",
    "        with open(f\"{file_path}ensemble({ensemble_filename}).jsonl\", mode='w') as outfile:\n",
    "        # with open(f\"{file_path}ensemble.jsonl\", mode='w') as outfile:\n",
    "            for entry in final_results:\n",
    "                json.dump(entry, outfile, ensure_ascii=False)\n",
    "                outfile.write('\\n')\n",
    "\n",
    "    elif len(file_list)>3:\n",
    "        with open(f\"{file_path}v2-ensemble({ensemble_filename}).jsonl\", mode='w') as outfile:\n",
    "        # with open(f\"{file_path}v2-ensemble.jsonl\", mode='w') as outfile:\n",
    "            for entry in final_results:\n",
    "                json.dump(entry, outfile, ensure_ascii=False)\n",
    "                outfile.write('\\n')\n",
    "\n",
    "    return final_results\n",
    "\n",
    "\n",
    "file_path = '../outputs/'\n",
    "# file_list = ['32.jsonl', '11.jsonl', '5.jsonl', '17.jsonl'] # # foundation 모델이 같아도 전처리 기법이 다른 top-4 모델\n",
    "# file_list = ['32.jsonl', '5.jsonl', '17.jsonl'] # foundation 모델이 서로 다른 top-3 모델\n",
    "# file_list = ['32.jsonl', '25.jsonl', '31.jsonl', '34.jsonl', '26.jsonl', '30.jsonl', '35.jsonl', '28.jsonl'] # public test score top-8 모델\n",
    "# file_list = ['32.jsonl', '25.jsonl', '31.jsonl', '34.jsonl', '26.jsonl'] # public test score top-5 모델\n",
    "# file_list = ['32.jsonl', '25.jsonl', '31.jsonl'] # public test score top-3 모델\n",
    "# file_list = ['32.jsonl', '25.jsonl', '31.jsonl', '71.jsonl'] # public test score top-3 모델 + 특정 결과\n",
    "\n",
    "# LSTM a90 b32 d87 e83 lr25\n",
    "# (2) LSTMv2 a90 b32 d87 e83 lr25\n",
    "# file_list = ['90.jsonl', '32.jsonl', '87.jsonl', '83.jsonl', '25.jsonl'] # public test score top-5 모델  (ensemble 제외, 정확히 top-5는 아님)\n",
    "\n",
    "# Inception top-8 = 455\n",
    "# (1) InceptionV2 top-8 = 455\n",
    "# file_list = ['57.jsonl', '49.jsonl', '45.jsonl', '48.jsonl', '90.jsonl', '47.jsonl', '32.jsonl', '87.jsonl'] # 앙상블을 포함해서 public test score top-8 모델  (87.9 이상 모델 9개 전부)\n",
    "\n",
    "# LSTM a90 b32 lr25 d31 epo56 (미제출)\n",
    "# (3) LSTMv2 a90 b32 lr25 d31 epo56 (미제출)\n",
    "# file_list = ['90.jsonl', '32.jsonl', '25.jsonl', '31.jsonl', '56.jsonl'] # 현재 1등한 57번 모델의 구성에 90번 모델 추가\n",
    "\n",
    "# Inception 90+57 (미제출)\n",
    "# file_list = ['90.jsonl', '57.jsonl'] # 현재 1등한 57번 모델과 90번 모델 추가\n",
    "\n",
    "\n",
    "    \n",
    "file_path = '../outputs/beomi-KcELECTRA-base-v2022/removing_all-stratified_10folds-ES_patience5-ASL_Loss-lr2_5-b64/'\n",
    "file_list = [f\"fold_{n}-test_output.jsonl\" for n in range(10)] # 10-fold 학습 결과\n",
    "\n",
    "\n",
    "file_list = [file_path + file_name for file_name in file_list]\n",
    "\n",
    "\n",
    "character_list = [\"removing_nothing-stratified_10folds-ES_patience5-ASL_Loss-lr2_5-b64\", \n",
    "                  \"removing_emoji-stratified_10folds-ES_patience5-ASL_Loss-lr2_5-b64\",\n",
    "                  \"removing_all-stratified_10folds-ES_patience5-ASL_Loss-lr2_5-b64\"\n",
    "                 ]\n",
    "\n",
    "# micro-ensemble\n",
    "# file_list = []\n",
    "# for char in character_list:\n",
    "#     tmp_path = f'../outputs/beomi-KcELECTRA-base-v2022/{char}/'\n",
    "#     tmp_list = [f\"fold_{n}-test_output.jsonl\" for n in range(10)] # 10-fold 학습 결과\n",
    "#     tmp_list = [tmp_path + tmp_name for tmp_name in tmp_list]\n",
    "#     file_list.extend(tmp_list)\n",
    "# file_path = \"../outputs/beomi-KcELECTRA-base-v2022/\"\n",
    "\n",
    "# macro-ensemble\n",
    "# file_list = []\n",
    "# for char in character_list:\n",
    "#     tmp_path = f'../outputs/beomi-KcELECTRA-base-v2022/{char}/'\n",
    "#     tmp_list = [f\"ensemble({char}).jsonl\"] # 10-fold 학습 결과\n",
    "#     tmp_list = [tmp_path + tmp_name for tmp_name in tmp_list]\n",
    "#     file_list.extend(tmp_list)\n",
    "# file_path = \"../outputs/beomi-KcELECTRA-base-v2022/\"\n",
    "\n",
    "final_results = hard_voting(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ea7d71-e7c4-4add-9986-e1e769a7bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e107587-526a-4c92-968e-338f1545b361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01aa6c0-3cbf-4fd6-9d7d-0f8f6bbb938b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f72f92-ad9d-48df-a5c5-6188ad5556bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32396c-7b78-401b-bc28-92ab88292a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af76bc3e-d47e-4b46-b4e7-abeb168cc56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890a726-0dd3-4a69-acf7-d55efa241a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362e0b2f-4d32-48ea-a25e-d36c72fb8603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5cdeb-f2be-401d-b721-4cd491783f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
